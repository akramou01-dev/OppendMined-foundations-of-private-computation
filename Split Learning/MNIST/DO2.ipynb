{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcc8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy \n",
    "import torch \n",
    "from torchvision import datasets \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e002e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Starting Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[95mSTEP 1:\u001b[0m Send the following code to your Duet Partner!\n",
      "\n",
      "import syft as sy\n",
      "duet = sy.join_duet(loopback=True)\n",
      "\n",
      "♫♫♫ > Connecting...\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n",
      "\n",
      "`searchable` is deprecated please use `pointable` in futurees: 0  Request Handlers: 0                                \n",
      "♫♫♫ > DUET LIVE STATUS  *  Objects: 237  Requests: 0   Messages: 3980  Request Handlers: 1                                \r"
     ]
    }
   ],
   "source": [
    "duet = sy.duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40559af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, worker_list=None, n_workers=2):\n",
    "\n",
    "    if worker_list is None:\n",
    "        worker_list = list(range(0, n_workers))\n",
    "            \n",
    "    #counter to create the index of different data samples\n",
    "    idx = 0 \n",
    "    \n",
    "    #dictionary to accomodate the split data\n",
    "    dic_single_datasets = {}\n",
    "    for worker in worker_list: \n",
    "        \"\"\"\n",
    "        Each value is a list of three elements, to accomodate, in order: \n",
    "        - data examples (as tensors)\n",
    "        - label\n",
    "        - index \n",
    "        \"\"\"\n",
    "        dic_single_datasets[worker] = [] \n",
    "\n",
    "    \"\"\"\n",
    "    Loop through the dataset to split the data and labels vertically across workers. \n",
    "    Splitting method from @abbas5253: https://github.com/abbas5253/SplitNN-for-Vertically-Partitioned-Data/blob/master/distribute_data.py\n",
    "    \"\"\"\n",
    "    \n",
    "    label_list = []\n",
    "    index_list = []\n",
    "    for tensor, label in dataset:\n",
    "        height = tensor.shape[-1]//len(worker_list)\n",
    "        i = 0\n",
    "        for worker in worker_list[:-1]: \n",
    "            dic_single_datasets[worker].append(tensor[:, :, height * i : height * (i + 1)])\n",
    "            i += 1\n",
    "            \n",
    "        #add the value of the last worker / split\n",
    "        dic_single_datasets[worker_list[-1]].append(tensor[:, :, height * (i) : ])\n",
    "        label_list.append(torch.Tensor([label]))\n",
    "        index_list.append(torch.Tensor([idx]))\n",
    "        \n",
    "        idx += 1\n",
    "        \n",
    "    return dic_single_datasets, label_list, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3041fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5090746",
   "metadata": {},
   "outputs": [],
   "source": [
    "img , _ , _ = split_data(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1518eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.cat(img[1][:25_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43a8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rshp= img.view(img.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe4c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 392])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rshp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab73d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img,_,_ = split_data(valset)\n",
    "val_img = torch.cat(val_img[1][:5_000])\n",
    "val_img_rshp = val_img.view(val_img.shape[0],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d15725b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 392])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_img_rshp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "824a1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`searchable` is deprecated please use `pointable` in future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x1e426e07580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rshp.send(duet,searchable=True,tags=[\"DO2\"],description=\"This the MNIST dataset comming from the DO2 and contains 25_000 img\")\n",
    "val_img.send(duet,searchable=True,tags=[\"DO2_test\"],description=\"This the MNIST dataset (test) comming from the DO2 and contains 5_000 img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fabce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_img_rshp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5b2b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\syft\\lib\\torch\\uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5031d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
