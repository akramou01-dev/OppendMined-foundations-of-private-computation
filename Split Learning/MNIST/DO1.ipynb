{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f33855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy \n",
    "import torch \n",
    "from torchvision import datasets \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d24f94ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Starting Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following code to your Duet Partner!\n",
      "\n",
      "import syft as sy\n",
      "duet = sy.join_duet(loopback=True)\n",
      "\n",
      "â™«â™«â™« > Connecting...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duet  = sy.launch_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fb8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, worker_list=None, n_workers=2):\n",
    "\n",
    "    if worker_list is None:\n",
    "        worker_list = list(range(0, n_workers))\n",
    "            \n",
    "    #counter to create the index of different data samples\n",
    "    idx = 0 \n",
    "    \n",
    "    #dictionary to accomodate the split data\n",
    "    dic_single_datasets = {}\n",
    "    for worker in worker_list: \n",
    "        \"\"\"\n",
    "        Each value is a list of three elements, to accomodate, in order: \n",
    "        - data examples (as tensors)\n",
    "        - label\n",
    "        - index \n",
    "        \"\"\"\n",
    "        dic_single_datasets[worker] = [] \n",
    "\n",
    "    \"\"\"\n",
    "    Loop through the dataset to split the data and labels vertically across workers. \n",
    "    Splitting method from @abbas5253: https://github.com/abbas5253/SplitNN-for-Vertically-Partitioned-Data/blob/master/distribute_data.py\n",
    "    \"\"\"\n",
    "    \n",
    "    label_list = []\n",
    "    index_list = []\n",
    "    for tensor, label in dataset:\n",
    "        height = tensor.shape[-1]//len(worker_list)\n",
    "        i = 0\n",
    "        for worker in worker_list[:-1]: \n",
    "            dic_single_datasets[worker].append(tensor[:, :, height * i : height * (i + 1)])\n",
    "            i += 1\n",
    "            \n",
    "        #add the value of the last worker / split\n",
    "        dic_single_datasets[worker_list[-1]].append(tensor[:, :, height * (i) : ])\n",
    "        label_list.append(torch.Tensor([label]))\n",
    "        index_list.append(torch.Tensor([idx]))\n",
    "        \n",
    "        idx += 1\n",
    "        \n",
    "    return dic_single_datasets, label_list, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc56c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist\\MNIST\\raw\n",
      "\n",
      "Processing...\n",
      "â™«â™«â™« > DUET LIVE STATUS  *  Objects: 0  Requests: 0   Messages: 0  Request Handlers: 0                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('mnist', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e81c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [], 1: []}"
     ]
    }
   ],
   "source": [
    "img , _ , _ = split_data(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87009f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.cat(img[0][:25_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255fb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rshp= img.view(img.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d78635f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [], 1: []}\n"
     ]
    }
   ],
   "source": [
    "val_img,_,_ = split_data(valset)\n",
    "val_img = torch.cat(val_img[0][:5_000])\n",
    "val_img_rshp = val_img.view(val_img.shape[0],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca65b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`searchable` is deprecated please use `pointable` in future"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x16517326370>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rshp.send(duet,searchable=True,tags=[\"DO1\"],description=\"This the MNIST dataset comming from the DO1 and contains 25_000 img\")\n",
    "val_img.send(duet,searchable=True,tags=[\"DO1_test\"],description=\"This the MNIST dataset (test) comming from the DO1 and contains 5_000 img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28ecfa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 448e8111d76d4a9d8b85d3ce4f396f53&gt;</td>\n",
       "      <td>[DO1]</td>\n",
       "      <td>This the MNIST dataset comming from the DO1 an...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 9e60210e833748589481ffb03600f220&gt;</td>\n",
       "      <td>[DO1_test]</td>\n",
       "      <td>This the MNIST dataset (test) comming from the...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID        Tags  \\\n",
       "0  <UID: 448e8111d76d4a9d8b85d3ce4f396f53>       [DO1]   \n",
       "1  <UID: 9e60210e833748589481ffb03600f220>  [DO1_test]   \n",
       "\n",
       "                                         Description             object_type  \n",
       "0  This the MNIST dataset comming from the DO1 an...  <class 'torch.Tensor'>  \n",
       "1  This the MNIST dataset (test) comming from the...  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-14T02:39:39.843918+0100][CRITICAL][logger]][17964] You do not have permission to .get() Object with ID: <UID: 448e8111d76d4a9d8b85d3ce4f396f53>Please submit a request.\n",
      "[2021-08-14T02:39:39.844918+0100][CRITICAL][logger]][17964] You do not have permission to .get() Object with ID: <UID: 448e8111d76d4a9d8b85d3ce4f396f53>Please submit a request.\n"
     ]
    }
   ],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6010d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\syft\\lib\\torch\\uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9f80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
