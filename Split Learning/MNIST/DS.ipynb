{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35be55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy \n",
    "from torchvision import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb71fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-91' coro=<RTCSctpTransport._data_channel_flush() done, defined at C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aiortc\\rtcsctptransport.py:1645> exception=ConnectionError('Cannot send encrypted data, not connected')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\asyncio\\tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aiortc\\rtcsctptransport.py\", line 1676, in _data_channel_flush\n",
      "    await self._send(\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aiortc\\rtcsctptransport.py\", line 1333, in _send\n",
      "    await self._transmit()\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aiortc\\rtcsctptransport.py\", line 1556, in _transmit\n",
      "    await self._send_chunk(chunk)\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aiortc\\rtcsctptransport.py\", line 1340, in _send_chunk\n",
      "    await self.__transport._send_data(\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aiortc\\rtcdtlstransport.py\", line 659, in _send_data\n",
      "    raise ConnectionError(\"Cannot send encrypted data, not connected\")\n",
      "ConnectionError: Cannot send encrypted data, not connected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback Transaction.__retry()\n",
      "handle: <TimerHandle when=175432.546 Transaction.__retry()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\aioice\\stun.py\", line 306, in __retry\n",
      "    self.__future.set_exception(TransactionTimeout())\n",
      "  File \"C:\\Users\\21355\\Anaconda3\\envs\\pysyft\\lib\\asyncio\\futures.py\", line 270, in set_exception\n",
      "    raise exceptions.InvalidStateError(f'{self._state}: {self!r}')\n",
      "asyncio.exceptions.InvalidStateError: FINISHED: <Future finished result=(Message(messa...3\\xe6_;`\\x87'), ('192.168.1.5', 51574))>\n"
     ]
    }
   ],
   "source": [
    "duet1 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ce2a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4735be70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 448e8111d76d4a9d8b85d3ce4f396f53&gt;</td>\n",
       "      <td>[DO1]</td>\n",
       "      <td>This the MNIST dataset comming from the DO1 an...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 9e60210e833748589481ffb03600f220&gt;</td>\n",
       "      <td>[DO1_test]</td>\n",
       "      <td>This the MNIST dataset (test) comming from the...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID        Tags  \\\n",
       "0  <UID: 448e8111d76d4a9d8b85d3ce4f396f53>       [DO1]   \n",
       "1  <UID: 9e60210e833748589481ffb03600f220>  [DO1_test]   \n",
       "\n",
       "                                         Description             object_type  \n",
       "0  This the MNIST dataset comming from the DO1 an...  <class 'torch.Tensor'>  \n",
       "1  This the MNIST dataset (test) comming from the...  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e709f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 6332360e4add41e7a2804b4e78c98d5d&gt;</td>\n",
       "      <td>[DO2]</td>\n",
       "      <td>This the MNIST dataset comming from the DO2 an...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: e1c5269e2d464a42bc46f6ab41eaa69e&gt;</td>\n",
       "      <td>[DO2_test]</td>\n",
       "      <td>This the MNIST dataset (test) comming from the...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID        Tags  \\\n",
       "0  <UID: 6332360e4add41e7a2804b4e78c98d5d>       [DO2]   \n",
       "1  <UID: e1c5269e2d464a42bc46f6ab41eaa69e>  [DO2_test]   \n",
       "\n",
       "                                         Description             object_type  \n",
       "0  This the MNIST dataset comming from the DO2 an...  <class 'torch.Tensor'>  \n",
       "1  This the MNIST dataset (test) comming from the...  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0338c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = datasets.MNIST(\"mnist\",download=True,train=True).targets[:25_000]\n",
    "labels_val = datasets.MNIST(\"mnist\",download=True,train=False).targets[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b53b9049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39c1b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = duet1.store[0]\n",
    "val1 = duet1.store[1]\n",
    "\n",
    "train2 = duet2.store[0]\n",
    "val2 = duet2.store[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9f10296",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_1 = duet1.torch.utils.data.DataLoader(train1,batch_size = 128)\n",
    "dl1_val = duet1.torch.utils.data.DataLoader(val1,batch_size = 128)\n",
    "\n",
    "\n",
    "\n",
    "dl_2 = duet2.torch.utils.data.DataLoader(train2,batch_size = 128)\n",
    "dl2_val = duet2.torch.utils.data.DataLoader(val2,batch_size = 128)\n",
    "\n",
    "dl_local = torch.utils.data.DataLoader(labels,batch_size = 128)\n",
    "dl1_val_local = torch.utils.data.DataLoader(labels_val,batch_size = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "flexible-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to serialise our model we need to define it as below\n",
    "from torch import nn\n",
    "\n",
    "hidden_sizes = [128, 500]\n",
    "output_size = 10\n",
    "\n",
    "class SyNet_client(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_client, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin = self.torch_ref.nn.Linear(392,64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SyNet_server(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_server, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.lin3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.sft = nn.LogSoftmax(dim=1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.sft(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "illegal-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "model1 = SyNet_client(torch)\n",
    "model1_ptr = model1.send(duet1)\n",
    "opt1 = duet1.torch.optim.SGD(params=model1_ptr.parameters(),lr=0.01)\n",
    "\n",
    "#Model 2\n",
    "model2 = SyNet_client(torch)\n",
    "model2_ptr = model2.send(duet2)\n",
    "opt2 = duet2.torch.optim.SGD(params=model2_ptr.parameters(),lr=0.01)\n",
    "\n",
    "#Model 3\n",
    "model3 = SyNet_server(torch)\n",
    "local_opt = torch.optim.SGD(params=model3.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "positive-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([-0.4527, -0.0163, -0.6196, -0.0474, -0.1980, -0.2295, -0.0449, -0.0596,\n",
      "        -0.0317, -0.0734, -0.0163, -0.7956, -0.0116, -0.0907, -0.0290, -0.1606,\n",
      "        -0.0271, -0.1588, -0.6409, -0.8362, -0.1063, -0.0232, -0.7405, -0.0505,\n",
      "        -1.4806, -0.4328, -0.7322, -0.0059, -0.5703, -0.6529, -0.5769, -0.4653,\n",
      "        -0.0301, -0.1518, -0.2966, -0.9607, -0.0333, -0.0145, -0.4565, -0.0362,\n",
      "        -0.0159, -0.1980, -0.0681, -0.5092, -0.2630, -0.1591, -0.3414, -0.0445,\n",
      "        -0.5326, -0.0894, -0.1109, -0.0266, -0.0125, -1.0462, -0.5441, -0.1778,\n",
      "        -0.0275, -0.3368, -0.3869, -0.0620, -0.6880, -0.6127, -0.0832, -0.0465,\n",
      "        -1.3801, -0.9129, -0.0147, -0.0150, -0.8006, -0.1135, -0.5652, -0.0788,\n",
      "        -0.0217, -0.0516, -0.0672, -0.0599, -0.3798, -0.0250, -0.2113, -0.0931,\n",
      "        -0.8149, -0.1366, -0.0067, -0.0873, -0.0300, -0.4572, -0.6545, -0.2022,\n",
      "        -0.0522, -0.1090, -0.0040, -0.0628, -0.1644, -0.0547, -0.0716, -0.0212,\n",
      "        -0.0248, -0.0704, -0.0527, -0.0969, -0.4093, -0.0806, -0.0248, -0.0168,\n",
      "        -0.1497, -0.0309, -0.0332, -0.0275, -0.3278, -0.2774, -0.0681, -0.4256,\n",
      "        -0.0128, -0.0494, -0.0098, -0.1093, -0.1600, -0.3736, -0.4065, -0.0067,\n",
      "        -0.9362, -0.0466, -0.0239, -0.0089, -0.0290, -0.4520, -0.0172, -0.1319],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 1, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        2, 2, 4, 3, 7, 7, 3, 8, 6, 7, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
      "        5, 3, 3, 0, 7, 1, 9, 8, 0, 9, 4, 1, 2, 4, 6, 0, 4, 5, 6, 1, 0, 0, 2, 7,\n",
      "        1, 6, 3, 0, 2, 1, 1, 7, 0, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
      "        7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 6, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n",
      "        7, 0, 2, 7, 1, 8, 6, 4]))\n",
      "tensor(0.4088, grad_fn=<NllLossBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.0374, -0.0517, -0.0456, -0.0785, -0.6101, -0.2842, -0.9487, -0.0892,\n",
      "        -0.2468, -0.3808, -1.2262, -0.0250, -0.4021, -0.9079, -0.1338, -0.6211,\n",
      "        -0.3650, -0.3305, -0.4427, -0.0539, -0.9401, -0.0869, -0.5211, -0.0136,\n",
      "        -0.0217, -0.2166, -0.3705, -0.0125, -0.0493, -0.1161, -1.0951, -0.0341,\n",
      "        -1.2248, -1.2542, -0.1771, -0.0708, -0.0552, -0.0065, -0.0469, -0.1285,\n",
      "        -1.1994, -0.0819, -0.0645, -0.0294, -0.5549, -0.8149, -0.0161, -0.4782,\n",
      "        -0.1522, -0.0295, -1.3625, -0.2096, -0.7629, -0.9983, -0.5511, -0.1150,\n",
      "        -0.0155, -0.0455, -0.1086, -0.2818, -0.5728, -0.4389, -0.1511, -0.4417,\n",
      "        -0.0188, -0.1636, -0.0477, -0.1394, -0.1832, -0.3431, -0.6726, -0.1862,\n",
      "        -0.1215, -0.1086, -0.3761, -0.3275, -0.2102, -0.0434, -0.0562, -0.8179,\n",
      "        -0.0185, -0.0479, -0.7346, -0.0146, -0.9036, -0.0088, -0.0198, -0.0109,\n",
      "        -0.3925, -0.0597, -0.0727, -0.0579, -0.0630, -0.0262, -0.1222, -0.2499,\n",
      "        -0.6478, -0.2563, -0.1240, -0.1301, -0.7746, -0.0474, -0.0936, -0.0205,\n",
      "        -0.5955, -0.0178, -0.2817, -0.0292, -0.0820, -0.0442, -0.0709, -0.4857,\n",
      "        -0.7807, -0.0633, -0.0690, -0.0746, -0.4875, -0.0231, -0.7517, -0.2306,\n",
      "        -0.1383, -0.0395, -1.1976, -0.0357, -0.0242, -0.0260, -0.2636, -0.2005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 6, 3, 4, 1, 9, 4, 3, 3, 8, 5, 4, 7, 9, 4, 2, 8, 5, 8, 6, 9, 3, 4, 6,\n",
      "        1, 9, 9, 6, 0, 3, 4, 2, 9, 2, 9, 4, 4, 6, 4, 9, 1, 0, 9, 2, 9, 1, 1, 5,\n",
      "        9, 1, 0, 3, 1, 3, 3, 9, 1, 7, 6, 2, 8, 2, 2, 5, 0, 7, 4, 9, 7, 8, 3, 2,\n",
      "        1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 5, 1, 9, 2, 7, 3, 0, 4, 6, 5, 2, 6, 4, 7,\n",
      "        7, 8, 9, 9, 5, 0, 7, 1, 6, 2, 0, 3, 5, 4, 6, 5, 1, 6, 3, 7, 8, 8, 5, 9,\n",
      "        1, 0, 9, 1, 2, 2, 5, 3]))\n",
      "tensor(0.5055, grad_fn=<NllLossBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.8523, -0.0235, -0.0505, -0.3742, -0.4036, -0.0252, -0.3131, -0.0085,\n",
      "        -0.9297, -0.0478, -1.0244, -0.5476, -0.0954, -0.0256, -0.0875, -0.0435,\n",
      "        -0.5293, -0.6663, -1.3062, -0.0402, -0.0308, -0.0062, -0.4416, -0.0462,\n",
      "        -0.2904, -0.0173, -1.0853, -0.0091, -0.4705, -0.2837, -0.0274, -0.9715,\n",
      "        -0.0075, -0.0404, -0.0205, -0.0432, -1.1710, -0.0124, -0.1654, -0.1766,\n",
      "        -0.0122, -0.0467, -0.0775, -0.0935, -0.5663, -0.0422, -0.0254, -0.0033,\n",
      "        -0.4776, -0.0457, -0.3089, -0.0313, -0.0057, -0.0466, -0.0337, -0.0367,\n",
      "        -0.2185, -0.2488, -0.1378, -0.0325, -0.4468, -0.0140, -0.5370, -0.1877,\n",
      "        -0.0141, -0.0213, -0.4614, -0.0954, -0.0897, -0.0097, -0.0153, -0.0406,\n",
      "        -0.1332, -0.0334, -0.0342, -0.0459, -0.2422, -0.1314, -0.4961, -0.1470,\n",
      "        -0.3073, -0.0165, -0.3867, -0.0038, -0.4305, -0.0344, -0.3248, -0.4176,\n",
      "        -0.4666, -0.0570, -0.7048, -0.0125, -0.1379, -0.0045, -0.1174, -0.2561,\n",
      "        -0.5378, -0.0448, -0.6241, -0.1576, -0.0394, -0.1254, -0.1318, -0.0049,\n",
      "        -0.1538, -0.0967, -0.1973, -0.0567, -0.6660, -0.0036, -0.0416, -0.0251,\n",
      "        -0.9312, -0.0885, -0.2639, -0.0429, -0.1631, -0.0332, -0.4452, -0.0223,\n",
      "        -0.9328, -0.0179, -0.0075, -0.0543, -0.7607, -0.0079, -0.1142, -0.0561],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 4, 7, 5, 0, 6, 0, 7, 9, 8, 3, 9, 7, 1, 1, 4, 4, 5, 2, 4, 1, 2, 2, 3,\n",
      "        9, 3, 5, 0, 3, 9, 6, 3, 7, 4, 1, 3, 4, 0, 4, 8, 0, 4, 3, 6, 8, 7, 6, 0,\n",
      "        7, 7, 0, 7, 2, 1, 1, 6, 8, 9, 4, 1, 5, 2, 2, 9, 0, 3, 9, 6, 7, 2, 0, 3,\n",
      "        5, 4, 3, 6, 5, 8, 9, 5, 4, 7, 4, 2, 9, 3, 4, 8, 9, 1, 9, 2, 8, 7, 9, 1,\n",
      "        8, 7, 4, 1, 3, 1, 1, 0, 2, 3, 9, 4, 9, 2, 1, 6, 8, 4, 1, 7, 4, 4, 9, 2,\n",
      "        8, 7, 2, 4, 4, 2, 1, 9]))\n",
      "tensor(0.3819, grad_fn=<NllLossBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.7007, -0.0665, -0.5402, -0.0874, -0.5582, -0.1055, -0.2896, -0.6533,\n",
      "        -0.0900, -0.0627, -0.9609, -0.0083, -0.1300, -0.0687, -0.0818, -0.0165,\n",
      "        -0.2696, -0.0325, -0.0667, -0.1004, -0.7756, -0.1041, -0.4149, -0.0630,\n",
      "        -0.0347, -0.1696, -0.0298, -0.0862, -0.7467, -0.0622, -0.6771, -0.1890,\n",
      "        -0.2006, -0.7705, -1.0301, -0.0908, -0.6562, -0.0117, -0.0339, -0.0815,\n",
      "        -0.2196, -0.5897, -0.7398, -0.0050, -0.1260, -0.0204, -0.1089, -0.0586,\n",
      "        -0.0796, -0.5249, -0.7786, -0.0128, -0.7024, -0.2456, -0.1506, -0.2064,\n",
      "        -0.0291, -0.0838, -0.0938, -0.1040, -0.3038, -0.0239, -0.9353, -0.1256,\n",
      "        -0.0373, -0.0822, -0.0624, -0.0448, -0.1989, -0.1064, -0.0419, -0.0440,\n",
      "        -0.1796, -0.1432, -0.0411, -0.4789, -0.1220, -0.0423, -0.0032, -0.2057,\n",
      "        -0.2262, -0.0118, -0.1012, -0.0132, -0.3055, -0.2778, -0.6601, -0.1032,\n",
      "        -0.6272, -0.0918, -0.0602, -0.0756, -0.9347, -0.0138, -0.4030, -0.1407,\n",
      "        -0.4901, -0.0533, -0.3022, -0.1879, -0.0626, -0.8916, -0.6311, -0.1760,\n",
      "        -0.6438, -0.2070, -0.1231, -0.5365, -0.1689, -0.0265, -0.0765, -0.1061,\n",
      "        -0.0728, -0.9596, -0.0279, -0.0347, -0.1709, -0.5241, -0.3033, -0.6698,\n",
      "        -0.1988, -0.0385, -0.5137, -0.1879, -0.1448, -0.7647, -0.0733, -0.5356],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([7, 2, 8, 7, 6, 9, 2, 2, 3, 8, 1, 6, 5, 1, 1, 0, 2, 6, 4, 5, 3, 3, 1, 5,\n",
      "        1, 9, 2, 7, 4, 4, 6, 8, 1, 5, 4, 9, 5, 6, 7, 9, 9, 3, 9, 0, 9, 0, 6, 6,\n",
      "        2, 3, 9, 0, 7, 5, 4, 8, 0, 9, 4, 1, 1, 8, 7, 1, 2, 6, 1, 0, 3, 0, 1, 1,\n",
      "        8, 2, 0, 9, 9, 4, 0, 5, 0, 6, 1, 7, 7, 8, 5, 9, 1, 0, 5, 1, 9, 2, 7, 3,\n",
      "        5, 4, 9, 7, 1, 8, 3, 9, 6, 0, 3, 1, 1, 2, 0, 3, 5, 7, 6, 8, 7, 9, 5, 8,\n",
      "        5, 7, 6, 1, 1, 8, 1, 7]))\n",
      "tensor(0.4416, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-2bdde737dcd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0ma1_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma1_ptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0ma2_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\syft\\core\\pointer\\pointer.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, request_block, timeout_secs, reason, delete_obj, verbose)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete_obj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelete_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             response_status = self.request(\n\u001b[0m\u001b[0;32m    272\u001b[0m                 \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\syft\\core\\pointer\\pointer.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, reason, block, timeout_secs, verbose)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# wait long enough for it to arrive and trigger a handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for in1, in2, label in zip(dl_1, dl_2, dl_local):\n",
    "        opt1.zero_grad()\n",
    "        opt2.zero_grad()\n",
    "        local_opt.zero_grad()\n",
    "\n",
    "        a1_ptr = model1_ptr(in1)\n",
    "        a1 = a1_ptr.clone().get(request_block=True)\n",
    "\n",
    "        a2_ptr = model2_ptr(in2)\n",
    "        a2 = a2_ptr.clone().get(request_block=True)\n",
    "        \n",
    "        a = torch.cat((a1, a2), 1)\n",
    "        y = model3(a)\n",
    "        \n",
    "        \n",
    "        criterion = nn.NLLLoss()\n",
    "        loss = criterion(y, label.long())\n",
    "        print(y.max(1))\n",
    "        train_correct += y.max(1)[1].eq(label).sum().item()\n",
    "        train_total += y.shape[0]\n",
    "        print(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        g1_ptr = a1.grad.clone().send(duet1)\n",
    "        g2_ptr = a2.grad.clone().send(duet2)\n",
    "        \n",
    "        a1_ptr.backward(g1_ptr)\n",
    "        a2_ptr.backward(g2_ptr)\n",
    "        \n",
    "        local_opt.step()\n",
    "        opt1.step()\n",
    "        opt2.step()\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for in_val1, in_val2, label_val in zip(dl_1val, dl_2val, dl_localval):\n",
    "        a1_ptr = model1_ptr(in_val1)\n",
    "        a1 = a1_ptr.clone().get(request_block=True)\n",
    "\n",
    "        a2_ptr = model2_ptr(in_val2)\n",
    "        a2 = a2_ptr.clone().get(request_block=True)\n",
    "\n",
    "        a = torch.cat((a1, a2), 1)\n",
    "        y = model3(a)\n",
    "\n",
    "        correct += y.max(1)[1].eq(label_val).sum().item()\n",
    "        total += y.shape[0]\n",
    "    print(f\"Train Accuracy: {100*train_correct/train_total:.3f}%\")\n",
    "    print(f\"Val Accuracy: {100*correct/total:.3f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-exemption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aff295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
